{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kittonn/biobotanix/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8VWh7LHzS1B"
      },
      "source": [
        "# Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUI1IyOpxz74"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9CDIKOlx4Bs"
      },
      "outputs": [],
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQWSMkmrx8-U"
      },
      "outputs": [],
      "source": [
        "! cp /content/drive/MyDrive/linear/kaggle.json ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piKHir6VyHNc"
      },
      "outputs": [],
      "source": [
        "! kaggle datasets download -d aryashah2k/indian-medicinal-leaves-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NJbcq5_YBRH"
      },
      "outputs": [],
      "source": [
        "! unzip /content/indian-medicinal-leaves-dataset.zip -d ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdxFiZ2CY9s_"
      },
      "source": [
        "# Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHhnivnfariD"
      },
      "outputs": [],
      "source": [
        "! pip install efficientnet_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onXl0yiQZCTW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "from torch.utils.data import random_split, SubsetRandomSampler\n",
        "from torchvision import datasets, transforms, models\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.utils import make_grid\n",
        "from pytorch_lightning import LightningModule\n",
        "from pytorch_lightning import Trainer\n",
        "import pytorch_lightning as pl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from PIL import Image\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9hgyx7xY27p"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rqN7IA0i-tf"
      },
      "outputs": [],
      "source": [
        "transform=transforms.Compose([\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.Resize(224),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = \"/content/Indian Medicinal Leaves Image Datasets/Medicinal Leaf dataset\"\n",
        "dataset0=datasets.ImageFolder(root=data_dir,transform=None)\n",
        "\n",
        "class_names=dataset0.classes\n",
        "print(class_names)\n",
        "print(len(class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DataModule(pl.LightningDataModule):\n",
        "\n",
        "    def __init__(self, transform=transform, batch_size=32):\n",
        "        super().__init__()\n",
        "        self.root_dir = \"/content/Indian Medicinal Leaves Image Datasets/Medicinal Leaf dataset\"\n",
        "        self.transform = transform\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        dataset = datasets.ImageFolder(root=self.root_dir, transform=self.transform)\n",
        "        n_data = len(dataset)\n",
        "        n_train = int(0.8 * n_data)\n",
        "        n_test = n_data - n_train\n",
        "\n",
        "        train_dataset, test_dataset = torch.utils.data.random_split(dataset, [n_train, n_test])\n",
        "\n",
        "        self.train_dataset = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "        self.test_dataset = DataLoader(test_dataset, batch_size=self.batch_size)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return self.train_dataset\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return self.test_dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ConvolutionalNetwork(LightningModule):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ConvolutionalNetwork, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3, 1)\n",
        "        self.fc1 = nn.Linear(16 * 54 * 54, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 20)\n",
        "        self.fc4 = nn.Linear(20, len(class_names))\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = F.relu(self.conv1(X))\n",
        "        X = F.max_pool2d(X, 2, 2)\n",
        "        X = F.relu(self.conv2(X))\n",
        "        X = F.max_pool2d(X, 2, 2)\n",
        "        X = X.view(-1, 16 * 54 * 54)\n",
        "        X = F.relu(self.fc1(X))\n",
        "        X = F.relu(self.fc2(X))\n",
        "        X = F.relu(self.fc3(X))\n",
        "        X = self.fc4(X)\n",
        "        return F.log_softmax(X, dim=1)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, train_batch, batch_idx):\n",
        "        X, y = train_batch\n",
        "        y_hat = self(X)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "        pred = y_hat.argmax(dim=1, keepdim=True)\n",
        "        acc = pred.eq(y.view_as(pred)).sum().item() / y.shape[0]\n",
        "        self.log(\"train_loss\", loss)\n",
        "        self.log(\"train_acc\", acc)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, val_batch, batch_idx):\n",
        "        X, y = val_batch\n",
        "        y_hat = self(X)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "        pred = y_hat.argmax(dim=1, keepdim=True)\n",
        "        acc = pred.eq(y.view_as(pred)).sum().item() / y.shape[0]\n",
        "        self.log(\"val_loss\", loss)\n",
        "        self.log(\"val_acc\", acc)\n",
        "\n",
        "    def test_step(self, test_batch, batch_idx):\n",
        "        X, y = test_batch\n",
        "        y_hat = self(X)\n",
        "        loss = F.cross_entropy(y_hat, y)\n",
        "        pred = y_hat.argmax(dim=1, keepdim=True)\n",
        "        acc = pred.eq(y.view_as(pred)).sum().item() / y.shape[0]\n",
        "        self.log(\"test_loss\", loss)\n",
        "        self.log(\"test_acc\", acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epoch_list = []\n",
        "loss_list = []\n",
        "accuracy_list = []\n",
        "class PlotProgressCallback(pl.Callback):\n",
        "    def on_train_epoch_end(self, trainer, pl_module):\n",
        "        epoch = trainer.current_epoch\n",
        "        loss = trainer.callback_metrics.get('train_loss').item()  \n",
        "        accuracy = trainer.callback_metrics.get('train_acc').item()\n",
        "        plot_progress(epoch, loss, accuracy)\n",
        "\n",
        "def plot_progress(epoch, loss, accuracy):\n",
        "    epoch_list.append(epoch)\n",
        "    loss_list.append(loss)\n",
        "    accuracy_list.append(accuracy)\n",
        "    plt.clf()\n",
        "\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(epoch_list, loss_list, label='Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.plot(epoch_list, accuracy_list, label='Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50iY_h93dsPf"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGzQ8zJjW42d"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    datamodule = DataModule()\n",
        "    datamodule.setup()\n",
        "    model = ConvolutionalNetwork()\n",
        "    trainer = pl.Trainer(max_epochs=20 ,callbacks=[PlotProgressCallback()])\n",
        "    trainer.fit(model, datamodule)\n",
        "    datamodule.setup(stage='test')\n",
        "    test_loader = datamodule.test_dataloader()\n",
        "    trainer.test(dataloaders=test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for images, labels in datamodule.train_dataloader():\n",
        "    break\n",
        "im=make_grid(images,nrow=16)\n",
        "\n",
        "plt.figure(figsize=(12,12))\n",
        "plt.imshow(np.transpose(im.numpy(),(1,2,0)))\n",
        "\n",
        "inv_normalize=transforms.Normalize(mean=[-0.485/0.229,-0.456/0.224,-0.406/0.225],\n",
        "                                   std=[1/0.229,1/0.224,1/0.225])\n",
        "im=inv_normalize(im)\n",
        "\n",
        "plt.figure(figsize=(12,12))\n",
        "plt.imshow(np.transpose(im.numpy(),(1,2,0)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cpu\")\n",
        "\n",
        "model.eval()\n",
        "y_true=[]\n",
        "y_pred=[]\n",
        "with torch.no_grad():\n",
        "    for test_data in datamodule.test_dataloader():\n",
        "        test_images, test_labels = test_data[0].to(device), test_data[1].to(device)\n",
        "        pred = model(test_images).argmax(dim=1)\n",
        "        for i in range(len(pred)):\n",
        "            y_true.append(test_labels[i].item())\n",
        "            y_pred.append(pred[i].item())\n",
        "\n",
        "print(classification_report(y_true,y_pred,target_names=class_names,digits=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'convolutional_model.pt')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyO2XBdwiioZKJgg2moB391R",
      "collapsed_sections": [
        "F8VWh7LHzS1B"
      ],
      "include_colab_link": true,
      "mount_file_id": "1EsdHmQznU3ePlCRvyTNK2HXNq1Bdg7Ya",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
